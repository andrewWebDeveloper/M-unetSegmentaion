# -*- coding: utf-8 -*-
"""task 3 duplicate (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zUNgab6SET9PPYFFf6CtU30UDVsYY6ci
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load
imgs=[]
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk(r'C:\Users\research\Desktop\segmentaion\frames'):
    for filename in filenames:
        print(os.path.join(dirname,filename))
        imgs.append(os.path.join(dirname,filename))
        

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import sys
!{sys.executable} -m pip install opencv-python

len(imgs),imgs[2728]

len(imgs),imgs[2728]

train_files = glob(os.path.join(r'C:\Users\research\Desktop\segmentaion', "*.png"))

mask_files = glob(os.path.join(r'C:\Users\research\Desktop\segmentaion\masks', "*.png"))
dilate_files = glob(os.path.join(r'C:\Users\research\Desktop\segmentaion\masks', "*.png"))
train_files.sort()
mask_files.sort()
dilate_files.sort()
(len(train_files), \
 len(mask_files), \
 len(dilate_files))

train_files[2728],mask_files[2728]

def train_generator(data_frame, batch_size, train_path, aug_dict,
        image_color_mode="rgb",
        mask_color_mode="grayscale",
        image_save_prefix="image",
        mask_save_prefix="mask",
        save_to_dir=None,
        target_size=(512,512),
        seed=1):
    '''
    can generate image and mask at the same time use the same seed for
    image_datagen and mask_datagen to ensure the transformation for image
    and mask is the same if you want to visualize the results of generator,
    set save_to_dir = "your path"
    '''
    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)
    
    image_generator = image_datagen.flow_from_dataframe(
        data_frame,
        directory = train_path,
        x_col = "filename",
        class_mode = None,
        color_mode = image_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = image_save_prefix,
        seed = seed)

    mask_generator = mask_datagen.flow_from_dataframe(
        data_frame,
        directory = train_path,
        x_col = "dilate",
        class_mode = None,
        color_mode = mask_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = mask_save_prefix,
        seed = seed)

    train_gen = zip(image_generator, mask_generator)
    
    for (img, mask) in train_gen:
        img, mask = adjust_data(img, mask)
        yield (img,mask)

def adjust_data(img,mask):
    img = img / 255
    mask = mask / 255
    mask[mask > 0.5] = 1
    mask[mask <= 0.5] = 0
    
    return (img, mask)

def iou_loss(y_true, y_pred):
    return 1-iou(y_true, y_pred)

def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)

def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

def iou(y_true, y_pred):
    intersection = K.sum(K.abs(y_true * y_pred))
    sum_ = K.sum((y_true)) + K.sum((y_pred))
    jac = (intersection) / (sum_ - intersection)
    return jac

from tensorflow.keras.applications.vgg16 import VGG16

def segnet(input_size=(512, 512, 1)):
    
    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_size)
    
    # Encoding layer
    inp = Input(input_size)
    x = encoder.get_layer(name='block1_conv1')(inp)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block1_conv2')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D()(x)
    
    x = encoder.get_layer(name='block2_conv1')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block2_conv2')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D()(x)

    x = encoder.get_layer(name='block3_conv1')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block3_conv2')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block3_conv3')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D()(x)

    x = encoder.get_layer(name='block4_conv1')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block4_conv2')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block4_conv3')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D()(x)
    
    x = encoder.get_layer(name='block5_conv1')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block5_conv2')(x)
    x = BatchNormalization()(x)
    x = encoder.get_layer(name='block5_conv3')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D()(x)
    
    # Decoding Layer 
    x = UpSampling2D()(x)
    x = Conv2D(1024, (3, 3), padding='same', name='deconv1')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(1024, (3, 3), padding='same', name='deconv2')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(1024, (3, 3), padding='same', name='deconv3')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    
    x = UpSampling2D()(x)
    x = Conv2D(512, (3, 3), padding='same', name='deconv4')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(512, (3, 3), padding='same', name='deconv5')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(512, (3, 3), padding='same', name='deconv6')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)

    x = UpSampling2D()(x)
    x = Conv2D(256, (3, 3), padding='same', name='deconv7')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(256, (3, 3), padding='same', name='deconv8')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(256, (3, 3), padding='same', name='deconv9')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)

    x = UpSampling2D()(x)
    x = Conv2D(128, (3, 3), padding='same', name='deconv10')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(128, (3, 3), padding='same', name='deconv11')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    
    x = UpSampling2D()(x)
    x = Conv2D(64, (3, 3), padding='same', name='deconv12')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)
    x = Conv2D(64, (3, 3), padding='same', name='deconv13')(x)
    x = Activation('relu')(x)
    x = BatchNormalization()(x)

    x = Conv2D(1, (3, 3), padding='same', name='deconv14')(x)
    x = Activation('sigmoid')(x)
    pred = Reshape((512,512))(x)
    
    return Model(inputs=inp, outputs=pred)

def munet(input_size=(128, 128, 3)):
    inputs = Input(input_size)
    
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)

    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)
    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)

    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)
    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)
    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)
    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)

    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)
    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)

    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)

    return Model(inputs=[inputs], outputs=[conv10])

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import *

def res_block(inputs,filter_size):
    """
    res_block -- Residual block for building res path
    
    Arguments:
    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for residual block
    filter_size {int} -- convolutional filter size 
    
    Returns:
    add {<class 'tensorflow.python.framework.ops.Tensor'>} -- addition of two convolutional filter output  
    """
    # First Conv2D layer
    cb1 = Conv2D(filter_size,(3,3),padding = 'same',activation="relu")(inputs)
    # Second Conv2D layer parallel to the first one
    cb2 = Conv2D(filter_size,(1,1),padding = 'same',activation="relu")(inputs)
    # Addition of cb1 and cb2
    add = Add()([cb1,cb2])
    
    return add

def res_path(inputs,filter_size,path_number):
    """
    res_path -- residual path / modified skip connection
    
    Arguments:
    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for res path
    filter_size {int} -- convolutional filter size 
    path_number {int} -- path identifier 
    
    Returns:
    skip_connection {<class 'tensorflow.python.framework.ops.Tensor'>} -- final res path
    """
    # Minimum one residual block for every res path
    skip_connection = res_block(inputs, filter_size)
    
    # Two serial residual blocks for res path 2
    if path_number == 2:
        skip_connection = res_block(skip_connection,filter_size)
    
    # Three serial residual blocks for res path 1
    elif path_number == 1:
        skip_connection = res_block(skip_connection,filter_size)
        skip_connection = res_block(skip_connection,filter_size)
    
    return skip_connection

def decoder_block(inputs, mid_channels, out_channels):
    
    """
    decoder_block -- decoder block formation
    
    Arguments:
    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for decoder block
    mid_channels {int} -- no. of mid channels 
    out_channels {int} -- no. of out channels
    
    Returns:
    db {<class 'tensorflow.python.framework.ops.Tensor'>} -- returning the decoder block
    """
    conv_kwargs = dict(
        activation='relu',
        padding='same',
        kernel_initializer='he_normal',
        data_format='channels_last'  
    )
    
    # Upsampling (nearest neighbor interpolation) layer
    db = UpSampling2D(size=(2, 2))(inputs)
    # First conv2D layer 
    db = Conv2D(mid_channels, 3, **conv_kwargs)(db)
    # Second conv2D layer
    db = Conv2D(out_channels, 3, **conv_kwargs)(db)

    return db

def TransResUNet(input_size=(512, 512, 3)):
    """
    TransResUNet -- main architecture of TransResUNet
    
    Arguments:
    input_size {tuple} -- size of input image
    
    Returns:
    model {<class 'tensorflow.python.keras.engine.training.Model'>} -- final model
    """
    
    # Input 
    inputs = Input(input_size)
    inp = inputs
    input_shape = input_size
    
    # Handling input channels 
    # input with 1 channel will be converted to 3 channels to be compatible with VGG16 pretrained encoder 
    if input_size[-1] < 3:
        inp = Conv2D(3, 1)(inputs)                         
        input_shape = (input_size[0], input_size[0], 3)  
    else:
        inp = inputs
        input_shape = input_size

    # VGG16 with imagenet weights
    encoder = VGG16(include_top=False, weights='imagenet', input_shape=(512,512,3))
       
    # First encoder block
    enc1 = encoder.get_layer(name='block1_conv1')(inp)
    enc1 = encoder.get_layer(name='block1_conv2')(enc1)
    # Second encoder block
    enc2 = MaxPooling2D(pool_size=(2, 2))(enc1)
    enc2 = encoder.get_layer(name='block2_conv1')(enc2)
    enc2 = encoder.get_layer(name='block2_conv2')(enc2)
    # Third encoder block
    enc3 = MaxPooling2D(pool_size=(2, 2))(enc2)
    enc3 = encoder.get_layer(name='block3_conv1')(enc3)
    enc3 = encoder.get_layer(name='block3_conv2')(enc3)
    enc3 = encoder.get_layer(name='block3_conv3')(enc3)
    # Forth encoder block
    enc4 = MaxPooling2D(pool_size=(2, 2))(enc3)
    enc4 = encoder.get_layer(name='block4_conv1')(enc4)
    enc4 = encoder.get_layer(name='block4_conv2')(enc4)
    enc4 = encoder.get_layer(name='block4_conv3')(enc4)

    # Center block
    center = MaxPooling2D(pool_size=(2, 2))(enc4)
    center = decoder_block(center, 512, 256)

    # Decoder block corresponding to forth encoder
    res_path4 = res_path(enc4,256,4)
    dec4 = concatenate([res_path4, center], axis=3)
    dec4 = decoder_block(dec4, 512, 64)
    # Decoder block corresponding to third encoder
    res_path3 = res_path(enc3,128,3)
    dec3 = concatenate([res_path3, dec4], axis=3)
    dec3 = decoder_block(dec3, 256, 64)
    # Decoder block corresponding to second encoder
    res_path2 = res_path(enc2,64,2)
    dec2 = concatenate([res_path2, dec3], axis=3)
    dec2 = decoder_block(dec2, 128, 64)
    # Final Block concatenation with first encoded feature 
    res_path1 = res_path(enc1,32,1)
    dec1 = concatenate([res_path1, dec2], axis=3)
    dec1 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(dec1)
    dec1 = ReLU()(dec1)

    # Output
    out = Conv2D(1, 1)(dec1)
    out = Activation('sigmoid')(out)  
    
    # Final model
    model = Model(inputs=[inputs], outputs=[out])
    
    return model

import pandas
from sklearn.model_selection import KFold

df = pandas.DataFrame(data={"filename": train_files, 'mask' : mask_files, 'dilate' : dilate_files})

kf = KFold(n_splits = 5, shuffle=False)

BATCH_SIZE=4
train_generator_args = dict(rotation_range=0.2,
                            width_shift_range=0.05,
                            height_shift_range=0.05,
                            shear_range=0.05,
                            zoom_range=0.05,
                            horizontal_flip=True,
                            fill_mode='nearest')

histories = []
losses = []
accuracies = []
dicecoefs = []
ious = []

for k, (train_index, test_index) in enumerate(kf.split(df)):
    train_data_frame = df.iloc[train_index]
    test_data_frame = df.iloc[test_index]
    
    train_gen = train_generator(train_data_frame, BATCH_SIZE,
                                None,
                                train_generator_args,
                                target_size=(512,512))

    test_gener = train_generator(test_data_frame, BATCH_SIZE,
                                None,
                                train_generator_args,
                                target_size=(512,512))

    model = segnet(input_size=(512,512,3))
    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, \
                      metrics=[iou, dice_coef, 'binary_accuracy'])
    model.summary()

    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_lung_seg.hdf5', 
                                       monitor='loss', 
                                       verbose=1, 
                                       save_best_only=True)
    #model = load_model('1_unet_lung_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef,'iou_loss':iou_loss})
    

    history = model.fit(train_gen,
                                  steps_per_epoch=len(train_data_frame) / BATCH_SIZE, 
                                  epochs=100, 
                                  callbacks=[model_checkpoint],
                                  validation_data = test_gener,
                                  validation_steps=len(test_data_frame) / BATCH_SIZE)
    
    model = load_model(str(k+1) + '_unet_lung_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef,'iou_loss':iou_loss})
    
    test_gen = train_generator(test_data_frame, BATCH_SIZE,
                                None,
                                train_generator_args,
                                target_size=(512,512))
    results = model.evaluate(test_gen, steps=len(test_data_frame))
    results = dict(zip(model.metrics_names,results))
    
    histories.append(history)
    accuracies.append(results['binary_accuracy'])
    losses.append(results['loss'])
    dicecoefs.append(results['dice_coef'])
    ious.append(results['iou'])

model = load_model('1_unet_lung_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})

for i in range(18):
    index = np.random.randint(0, len(train_files))
    img = cv2.imread(train_files[index])
    img = cv2.resize(img, (512,512))
    img = img / 255
    img = img[np.newaxis, :, :, :]
    pred = model.predict(img)

    plt.figure(figsize=(12,12))
    plt.subplot(1,3,1)
    plt.imshow(cv2.imread(train_files[index]))
    plt.title('Original Image')
    plt.subplot(1,3,2)
    plt.imshow(np.squeeze(cv2.imread(dilate_files[index])))
    plt.title('Original Mask')
    plt.subplot(1,3,3)
    plt.imshow(np.squeeze(pred) > .5,cmap='gray')
    plt.title('Prediction')
    plt.show()

import os
import zipfile
import numpy as np
import tensorflow as tf
from PIL import Image

from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

from skimage import io
from sklearn import cluster
import matplotlib.pyplot as plt
import cv2
import numpy as np

from skimage import io
from sklearn import cluster
import matplotlib.pyplot as plt
import cv2
import numpy as np
from os.path import splitext


import numpy as np
import matplotlib.pyplot as plt
import zipfile
from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D
from keras.models import Model, load_model
from keras.callbacks import ReduceLROnPlateau
from PIL import Image
import cv2
import tensorflow as tf
from tensorflow.keras.utils import get_custom_objects
from sklearn.cluster import KMeans
from keras.utils.vis_utils import plot_model

def get_segmentation_model():
    class FixedDropout(tf.keras.layers.Dropout):
        def _get_noise_shape(self, inputs):
            if self.noise_shape is None:
                return self.noise_shape

            symbolic_shape = tf.keras.backend.shape(inputs)
            noise_shape = [symbolic_shape[axis] if shape is None else shape
                           for axis, shape in enumerate(self.noise_shape)]
            return tuple(noise_shape)

    def DiceCoef(y_trues, y_preds, smooth=1e-5, axis=None):
        intersection = tf.reduce_sum(y_trues * y_preds, axis=axis)
        union = tf.reduce_sum(y_trues, axis=axis) + tf.reduce_sum(y_preds, axis=axis)
        return tf.reduce_mean((2*intersection+smooth) / (union + smooth))

    def DiceLoss(y_trues, y_preds):
        return 1.0 - DiceCoef(y_trues, y_preds)

    get_custom_objects().update({'swish': tf.keras.layers.Activation(tf.nn.swish)})
    get_custom_objects().update({'FixedDropout':FixedDropout})
    get_custom_objects().update({'DiceCoef' : DiceCoef})
    get_custom_objects().update({'DiceLoss' : DiceLoss})
    
    print('Load segmentation model...')
    model = tf.keras.models.load_model(r'C:\Users\research\Desktop\segmentaion')
    return model

def threshold_predictions(pred,threshold):
  indices=pred>threshold
  pred[indices]=True
  indices=pred!=True
  pred[indices]=False
  return pred

def getImage(path):
   img=cv2.imread(path)
   img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

  #img=cv2.cvtColor(img,cv2.COLOR_RGB)
   img= cv2.resize(img,(256,256), interpolation=cv2.INTER_LANCZOS4)
   img=np.expand_dims(img,axis=0)
   img=(img-img.min())/(img.max()-img.min())
   return img

model_kaggle=(r"C:\Users\research\Desktop\segmentaion")

!mkdir ..\input_c
!mkdir ..\input_c\Users\research\Desktop\segmentaion

#imgs[0].split('/')[1]

for i in imgs:
    name=i.split('/')[5]
    oldImage=getImage(i)
    x=model_kaggle.predict(oldImage)
    pred_th=threshold_predictions(x,0.1)
    res=cv2.imwrite('../input_c/segmentation/'+name,np.squeeze(oldImage*pred_th)*255)

img=getImage(r"C:\\Users\\research\\Desktop\\segmentaion\\frames\\Jun_coronacases_case10_111.png")
y=getImage(r"C:\\Users\\research\\Desktop\\segmentaion\\masks\\Jun_coronacases_case10_111.png")
#x=model_kaggle.predict(img)
#pred_th=threshold_predictions(x,0.1)
#fig= figsize = (15,15)
fig,ax = plt.subplots(1,2,figsize = (15,15))
ax[0].imshow(np.squeeze(img), cmap='BuPu_r')
#ax[1].imshow(np.squeeze(pred_th), cmap='gray')
#ax[2].imshow(np.squeeze(img*pred_th), cmap='gray')
ax[1].imshow(np.squeeze(y), cmap='BuPu_r')
plt.show()

img=getImage(r"C:\\Users\\research\\Desktop\\segmentaion\\frames\\Jun_coronacases_case10_111.png")
y=getImage(r"C:\\Users\\research\\Desktop\\segmentaion\\masks\\covid.png")
#x=model_kaggle.predict(img)
#pred_th=threshold_predictions(x,0.1)
#fig= figsize = (15,15)
fig,ax = plt.subplots(1,2,figsize = (15,15))
ax[0].imshow(np.squeeze(img), cmap='BuPu_r')
#ax[1].imshow(np.squeeze(pred_th), cmap='gray')
#ax[2].imshow(np.squeeze(img*pred_th), cmap='gray')
ax[1].imshow(np.squeeze(y), cmap='BuPu_r')
plt.show()

